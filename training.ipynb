{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7e7a05f-48a9-49d4-9414-3fbc04b693de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a052d2b7-e0ad-40db-bede-8596e346e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(degrees=40),        # ðŸ”„ different angles\n",
    "    transforms.RandomHorizontalFlip(p=0.5),       # â†” mirror\n",
    "    transforms.RandomVerticalFlip(p=0.5),         # â†• mirror\n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.2,\n",
    "        contrast=0.2,\n",
    "        saturation=0.2\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cb82e22-925d-4ad1-b631-aed42abbeba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dc2dd2e-5579-4da3-89bb-6b453ed73077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['apples', 'avocados', 'bananas', 'grapes', 'guava', 'limes', 'mangos', 'oranges', 'pineapples', 'watermelons']\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ImageFolder(\"dataset/train\", transform=train_transforms)\n",
    "test_dataset  = ImageFolder(\"dataset/test\", transform=test_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "print(\"Classes:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d074c98-c829-4ad6-bc98-07bb39b15e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e51ee15b-2841-467c-a2cc-6764b8b23383",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FruitCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 28 * 28, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b119dae-c02b-40a9-8a46-29ae731aa26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = FruitCNN(num_classes=len(class_names)).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35584973-069d-403c-890d-1ba60cbeb177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78f2b5f7-7f75-492e-971a-c6749625dc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] Loss: 3.0185 Train Acc: 88.06%\n",
      "Epoch [2/100] Loss: 3.6940 Train Acc: 85.45%\n",
      "Epoch [3/100] Loss: 2.5096 Train Acc: 91.42%\n",
      "Epoch [4/100] Loss: 2.9192 Train Acc: 87.31%\n",
      "Epoch [5/100] Loss: 2.4475 Train Acc: 89.55%\n",
      "Epoch [6/100] Loss: 2.5310 Train Acc: 89.93%\n",
      "Epoch [7/100] Loss: 2.2772 Train Acc: 91.42%\n",
      "Epoch [8/100] Loss: 2.8326 Train Acc: 89.55%\n",
      "Epoch [9/100] Loss: 3.4529 Train Acc: 86.57%\n",
      "Epoch [10/100] Loss: 3.2448 Train Acc: 88.81%\n",
      "Epoch [11/100] Loss: 3.1034 Train Acc: 86.94%\n",
      "Epoch [12/100] Loss: 2.2733 Train Acc: 92.16%\n",
      "Epoch [13/100] Loss: 2.7049 Train Acc: 88.06%\n",
      "Epoch [14/100] Loss: 2.4670 Train Acc: 89.18%\n",
      "Epoch [15/100] Loss: 2.9760 Train Acc: 90.67%\n",
      "Epoch [16/100] Loss: 2.4227 Train Acc: 91.42%\n",
      "Epoch [17/100] Loss: 2.8210 Train Acc: 90.67%\n",
      "Epoch [18/100] Loss: 2.5752 Train Acc: 91.42%\n",
      "Epoch [19/100] Loss: 2.1883 Train Acc: 92.91%\n",
      "Epoch [20/100] Loss: 2.6455 Train Acc: 88.81%\n",
      "Epoch [21/100] Loss: 1.4306 Train Acc: 94.03%\n",
      "Epoch [22/100] Loss: 2.1554 Train Acc: 89.93%\n",
      "Epoch [23/100] Loss: 1.5035 Train Acc: 94.03%\n",
      "Epoch [24/100] Loss: 1.6727 Train Acc: 92.16%\n",
      "Epoch [25/100] Loss: 2.9705 Train Acc: 89.18%\n",
      "Epoch [26/100] Loss: 2.8623 Train Acc: 88.43%\n",
      "Epoch [27/100] Loss: 2.8466 Train Acc: 90.67%\n",
      "Epoch [28/100] Loss: 2.1717 Train Acc: 90.30%\n",
      "Epoch [29/100] Loss: 1.6571 Train Acc: 93.28%\n",
      "Epoch [30/100] Loss: 2.1499 Train Acc: 93.66%\n",
      "Epoch [31/100] Loss: 2.5997 Train Acc: 91.79%\n",
      "Epoch [32/100] Loss: 2.2735 Train Acc: 91.42%\n",
      "Epoch [33/100] Loss: 3.3237 Train Acc: 88.81%\n",
      "Epoch [34/100] Loss: 2.5805 Train Acc: 90.67%\n",
      "Epoch [35/100] Loss: 2.9020 Train Acc: 89.93%\n",
      "Epoch [36/100] Loss: 2.6914 Train Acc: 91.04%\n",
      "Epoch [37/100] Loss: 2.3487 Train Acc: 91.04%\n",
      "Epoch [38/100] Loss: 2.4046 Train Acc: 90.30%\n",
      "Epoch [39/100] Loss: 1.9748 Train Acc: 91.42%\n",
      "Epoch [40/100] Loss: 2.0154 Train Acc: 92.54%\n",
      "Epoch [41/100] Loss: 1.8374 Train Acc: 91.42%\n",
      "Epoch [42/100] Loss: 1.1411 Train Acc: 96.27%\n",
      "Epoch [43/100] Loss: 1.6280 Train Acc: 94.03%\n",
      "Epoch [44/100] Loss: 1.9396 Train Acc: 92.91%\n",
      "Epoch [45/100] Loss: 1.7149 Train Acc: 91.79%\n",
      "Epoch [46/100] Loss: 1.9301 Train Acc: 92.16%\n",
      "Epoch [47/100] Loss: 2.3809 Train Acc: 91.79%\n",
      "Epoch [48/100] Loss: 3.3999 Train Acc: 87.31%\n",
      "Epoch [49/100] Loss: 2.1692 Train Acc: 91.04%\n",
      "Epoch [50/100] Loss: 1.7177 Train Acc: 93.28%\n",
      "Epoch [51/100] Loss: 2.2205 Train Acc: 90.30%\n",
      "Epoch [52/100] Loss: 2.3443 Train Acc: 91.79%\n",
      "Epoch [53/100] Loss: 1.7588 Train Acc: 93.28%\n",
      "Epoch [54/100] Loss: 1.5519 Train Acc: 96.27%\n",
      "Epoch [55/100] Loss: 1.6590 Train Acc: 92.16%\n",
      "Epoch [56/100] Loss: 1.6595 Train Acc: 94.03%\n",
      "Epoch [57/100] Loss: 2.0539 Train Acc: 89.93%\n",
      "Epoch [58/100] Loss: 1.1798 Train Acc: 96.64%\n",
      "Epoch [59/100] Loss: 2.9229 Train Acc: 90.67%\n",
      "Epoch [60/100] Loss: 1.8519 Train Acc: 93.66%\n",
      "Epoch [61/100] Loss: 1.8837 Train Acc: 91.04%\n",
      "Epoch [62/100] Loss: 2.0661 Train Acc: 91.04%\n",
      "Epoch [63/100] Loss: 2.5772 Train Acc: 92.54%\n",
      "Epoch [64/100] Loss: 3.0425 Train Acc: 91.04%\n",
      "Epoch [65/100] Loss: 2.5646 Train Acc: 89.18%\n",
      "Epoch [66/100] Loss: 2.0501 Train Acc: 91.42%\n",
      "Epoch [67/100] Loss: 1.8875 Train Acc: 92.91%\n",
      "Epoch [68/100] Loss: 1.6748 Train Acc: 94.78%\n",
      "Epoch [69/100] Loss: 1.4439 Train Acc: 94.40%\n",
      "Epoch [70/100] Loss: 1.7567 Train Acc: 94.03%\n",
      "Epoch [71/100] Loss: 1.9021 Train Acc: 91.42%\n",
      "Epoch [72/100] Loss: 1.7463 Train Acc: 92.91%\n",
      "Epoch [73/100] Loss: 1.4647 Train Acc: 92.54%\n",
      "Epoch [74/100] Loss: 1.3380 Train Acc: 94.03%\n",
      "Epoch [75/100] Loss: 1.7419 Train Acc: 94.40%\n",
      "Epoch [76/100] Loss: 2.1127 Train Acc: 92.16%\n",
      "Epoch [77/100] Loss: 2.0810 Train Acc: 91.79%\n",
      "Epoch [78/100] Loss: 1.5158 Train Acc: 94.40%\n",
      "Epoch [79/100] Loss: 1.3694 Train Acc: 92.91%\n",
      "Epoch [80/100] Loss: 1.4768 Train Acc: 94.40%\n",
      "Epoch [81/100] Loss: 1.7959 Train Acc: 95.90%\n",
      "Epoch [82/100] Loss: 0.7325 Train Acc: 97.39%\n",
      "Epoch [83/100] Loss: 1.2634 Train Acc: 94.78%\n",
      "Epoch [84/100] Loss: 1.0148 Train Acc: 95.15%\n",
      "Epoch [85/100] Loss: 1.4974 Train Acc: 95.90%\n",
      "Epoch [86/100] Loss: 1.6936 Train Acc: 94.78%\n",
      "Epoch [87/100] Loss: 2.4047 Train Acc: 90.30%\n",
      "Epoch [88/100] Loss: 1.5395 Train Acc: 93.28%\n",
      "Epoch [89/100] Loss: 0.9319 Train Acc: 97.39%\n",
      "Epoch [90/100] Loss: 1.1317 Train Acc: 95.52%\n",
      "Epoch [91/100] Loss: 1.1683 Train Acc: 95.90%\n",
      "Epoch [92/100] Loss: 1.1768 Train Acc: 95.15%\n",
      "Epoch [93/100] Loss: 0.9230 Train Acc: 95.90%\n",
      "Epoch [94/100] Loss: 1.1098 Train Acc: 95.52%\n",
      "Epoch [95/100] Loss: 1.9002 Train Acc: 93.66%\n",
      "Epoch [96/100] Loss: 1.7801 Train Acc: 93.28%\n",
      "Epoch [97/100] Loss: 2.0756 Train Acc: 92.16%\n",
      "Epoch [98/100] Loss: 1.4827 Train Acc: 92.16%\n",
      "Epoch [99/100] Loss: 1.5384 Train Acc: 94.03%\n",
      "Epoch [100/100] Loss: 2.6643 Train Acc: 92.91%\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        torch.save(model.state_dict(), \"fruit_classifier.pth\")\n",
    "        \n",
    "    train_acc = 100 * correct / total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "          f\"Loss: {running_loss:.4f} \"\n",
    "          f\"Train Acc: {train_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb906043-9734-4de0-9653-9cd1736b4714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Test Accuracy: 83.33%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"âœ… Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "816cd40d-3220-40fd-9d8c-5742663c4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"fruit_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9306d3ce-d50e-4723-9aa7-35777eb32b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Torch)",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
